这是力扣 (LeetCode) 第 1130 题，"叶值的最小代价生成树"。

### 1. LeetCode 1130: 叶值的最小代价生成树 - 闪亮登场！

*   **题目链接**: [https://leetcode.cn/problems/minimum-cost-tree-from-leaf-values/](https://leetcode.cn/problems/minimum-cost-tree-from-leaf-values/)
*   **难度等级**: 中等
*   **题型分类**: 动态规划 (Dynamic Programming), 栈 (Stack), 树 (Tree)

**小剧场开演：**

想象一下，你是一位建筑大师，手里拿到了一串数字，比如 `[6, 2, 4]`。这些数字呢，是未来一棵二叉树最底层的叶子节点的值，而且它们是按照从左到右的顺序排列的（也就是中序遍历的结果）。

你的任务有点特别：你要把这些叶子节点两两配对，形成父节点，然后这些新形成的父节点再继续配对，直到最后只剩一个根节点，构成一棵完整的二叉树。

关键来了！每当你组合两个节点（或者子树）形成一个新的父节点时，这个新的父节点的“建筑成本”是它左边子树中最大的叶子节点值 * 右边子树中最大的叶子节点值。而整棵树的总建筑成本，就是所有这些“非叶子”父节点（也就是我们一路合并上来的节点）的建筑成本之和。

你的目标是：找到一种合并方式，让这棵树的总建筑成本最低。

回到刚才的 `[6, 2, 4]`：
*   **方案一**: 先合并 `6` 和 `2`。
    *   叶子 `6` 和叶子 `2` 合并，新父节点的成本是 `6 * 2 = 12`。此时，这个父节点代表的子树中，最大的叶子是 `6`。
    *   然后，这个“新父节点”（代表的叶子最大值是6）和叶子 `4` 合并。新父节点的成本是 `6 * 4 = 24`。
    *   总成本 = `12 + 24 = 36`。
*   **方案二**: 先合并 `2` 和 `4`。
    *   叶子 `2` 和叶子 `4` 合并，新父节点的成本是 `2 * 4 = 8`。此时，这个父节点代表的子树中，最大的叶子是 `4`。
    *   然后，叶子 `6` 和这个“新父节点”（代表的叶子最大值是4）合并。新父节点的成本是 `6 * 4 = 24`。
    *   总成本 = `8 + 24 = 32`。

看！不同的合并顺序，成本不一样！`32` 比 `36` 更低。那么，对于更长的数字序列，我们怎么才能系统地找到那个“最省钱”的方案呢？

这就是这道题的魅力所在啦！它想考验我们，如何在一系列选择中，找到最优的组合策略。

### 2. 题型特征与识别：一眼看穿你的“芯”！

这类题目通常有以下一些“蛛丝马迹”：

*   **输入特征**:
    *   一个数组（通常是一维的），代表一系列元素或选择。
    *   题目中会提到“相邻”、“区间”、“子数组”、“子序列”等词汇，暗示操作与元素的顺序或连续性有关。
    *   数组的长度通常不会特别大（比如几百到几千），因为过于复杂的暴力枚举可能会超时。

*   **输出特征**:
    *   要求一个“最优值”，比如最小值、最大值、最长长度、方案数等。

*   **关键词**:
    *   “最小代价”、“最大收益”、“最优解”。
    *   “划分”、“合并”、“组合”。
    *   “子问题”：解决大问题依赖于解决小规模的同样问题。

*   **常见陷阱/迷惑点**:
    *   **贪心误区**: 很容易第一感觉是“每次找局部最优”，比如“每次都合并当前最小的两个叶子”或者“每次都合并乘积最小的两个相邻叶子”。但这种贪心策略往往行不通，因为当前的局部最优可能会导致后续更大的代价。就像我们例子中的 `[6,2,4]`，如果只看相邻的，`2*4=8` 比 `6*2=12` 小，但最终结果却依赖于这个选择如何影响后续。
    *   **状态定义**: 如果往动态规划想，如何定义 `dp` 状态是一个难点。是 `dp[i][j]` 代表区间 `[i, j]` 的最小代价吗？这个状态如何转移？

*   **“识题技巧”或“触发解法的条件”**:
    *   **“区间 + 最优值 + 合并/划分” => 动态规划的强烈信号**：当题目涉及到对一个区间进行操作（比如合并区间内的元素，或者将区间划分为两部分），并且要求这个操作序列的某种最优值（最小成本、最大收益等），这通常是区间DP的典型特征。你会思考，一个大区间的解，是否可以由小区间解组合而来。
    *   **“消除元素 + 寻找局部最优影响全局” => 栈的可能应用**：当问题涉及到不断地处理和“消除”元素，并且每次消除的决策会影响后续，特别是当需要考虑某个元素与其左右两侧元素的关系时，单调栈或者普通栈结构可能派上用场。比如，每次我们合并两个叶子，实际上是“消除”了它们，用一个新的值（它们的父节点成本，或者父节点所代表的子树的最大叶子）来参与后续的计算。

对于本题，`arr[i]` 是叶子节点的值，它们是中序遍历的结果。这意味着，最终形成的二叉树，其叶子节点从左到右的顺序必须和 `arr` 保持一致。当我们合并两个相邻的子树（或者叶子）时，实际上是在原数组 `arr` 中选择一个“分割点”，这个点左边的形成左子树，右边的形成右子树。

### 3. 解题思路：从“硬刚”到“智取”

#### A. 暴力法：硬着头皮枚举所有可能 (思路启发，通常会超时)

最直观的想法，就是尝试所有可能的合并顺序。
对于一个数组 `arr`，我们最后一步一定是将它分成了两部分 `arr[0...k]` 和 `arr[k+1...n-1]`，然后计算这两部分各自形成子树后的最大叶子值的乘积，再加上这两部分各自的最小代价。

这具有明显的递归结构：
`min_cost(arr)` = `min(min_cost(left_part) + min_cost(right_part) + max_leaf(left_part) * max_leaf(right_part))`  对于所有可能的分割点。

*   **基本情况**: 如果 `arr` 只有一个元素，它是叶子，成本是0。如果有两个元素 `[a, b]`，成本就是 `a * b`。
*   **递归**: 对于 `arr[i...j]`，我们可以尝试所有可能的分割点 `k` (从 `i` 到 `j-1`)。
    *   左边是 `arr[i...k]`，右边是 `arr[k+1...j]`。
    *   成本 = `solve(i, k) + solve(k+1, j) + max_val(i, k) * max_val(k+1, j)`
    *   其中 `solve(i, j)` 是区间 `arr[i...j]` 的最小代价，`max_val(i, j)` 是区间 `arr[i...j]` 中的最大叶子值。

这种方法涉及到大量的重复计算。比如在计算 `solve(0, 5)` 时，可能会计算 `solve(0, 2)`；在计算 `solve(0, 6)` 时，也可能需要 `solve(0, 2)`。这就是动态规划的用武之地！

#### B. 优化思路 → 动态规划 (DP)

既然有重复子问题，我们就可以用 DP 来记忆化搜索，或者自底向上填表。

*   **状态定义**: `dp[i][j]` 表示由叶子节点数组 `arr[i...j]`（闭区间）构成的子树的最小代价和。
*   **目标**: `dp[0][n-1]`，其中 `n` 是数组长度。
*   **状态转移方程**:
    为了计算 `dp[i][j]`，我们考虑最后一次合并发生在哪里。假设最后一次合并是将 `arr[i...k]` 和 `arr[k+1...j]` 这两段合并起来。
    那么，这次合并产生的成本是 `max(arr[i...k]) * max(arr[k+1...j])`。
    总成本就是 `dp[i][k] + dp[k+1][j] + max(arr[i...k]) * max(arr[k+1...j])`。
    我们需要遍历所有可能的 `k` (从 `i` 到 `j-1`)，取其中的最小值。
    所以，`dp[i][j] = min(dp[i][k] + dp[k+1][j] + max_val[i][k] * max_val[k+1][j])` for `k` from `i` to `j-1`.
    其中 `max_val[x][y]` 表示 `arr[x...y]` 中的最大值，这个可以预处理或者在循环中计算。

*   **初始化**:
    *   `dp[i][i] = 0` (单个叶子节点，没有非叶节点，成本为0)。
    *   `dp[i][i+1] = arr[i] * arr[i+1]` (两个叶子节点，成本是它们值的乘积)。 (其实这个也可以由通用公式在 `len=2` 时得到，当 `k=i` 时，`dp[i][i]=0`, `dp[i+1][i+1]=0`，所以 `dp[i][i+1] = 0 + 0 + arr[i] * arr[i+1]`)

*   **遍历顺序**: DP 的计算依赖于小区间的解。所以我们通常按照区间的长度 `len` 来遍历。
    *   `len` 从 2 到 `n`。
    *   对于每个 `len`，遍历起始点 `i` (从 0 到 `n-len`)。
    *   `j = i + len - 1`。
    *   然后遍历 `k` (从 `i` 到 `j-1`)。

**图示/比喻**:
想象你在玩积木。`dp[i][j]` 就是把第 `i` 块到第 `j` 块积木组合起来的最小“焊接费”。
要组合 `i` 到 `j`，你总得在某个地方 `k` 把它们分成两堆：`[i...k]` 和 `[k+1...j]`。
你先把这两小堆各自焊好（费用是 `dp[i][k]` 和 `dp[k+1][j]`），然后再把这两大块焊起来。最后这次焊接的费用，取决于左边那一大块里最大的那个原始积木块的值，和右边那一大块里最大的那个原始积木块的值，把它们乘起来。
你得试试所有可能的“分界点” `k`，看看从哪儿分最省钱。

**常见错误点/思维误区**:
*   **`max_val` 的计算**: `max_val[i][k]` 是指原始叶子值 `arr[i...k]` 中的最大值，而不是某个中间计算出的非叶节点的值。
*   **边界条件**: `k` 的取值范围，`i` 和 `j` 的取值范围要小心。

**DP复杂度**:
*   状态数量: `O(N^2)` 个 `dp[i][j]` 状态。
*   每个状态计算: 需要 `O(N)` 的时间来遍历 `k`。
*   预计算 `max_val[i][j]` 需要 `O(N^2)`。
*   总时间复杂度: `O(N^3)`。
*   空间复杂度: `O(N^2)` (存 `dp` 表和 `max_val` 表)。

对于 `N` 最大为 40 的情况，`40^3 = 64000`，是可以接受的。

#### C. 最终算法 → 单调栈优化 (Greedy with a Stack)

虽然动态规划 (DP) 能解决问题，但就像我们有时候找到了开车去某个地方的路线，后来发现还有一条风景更好、速度更快的“小路”一样，这道题也有一个更巧妙、更高效的解法，时间复杂度可以优化到 `O(N)`！这个解法有点像“逆向思维”，或者说“聪明的局部选择最终导向全局最优”的贪心策略。

**核心思想回顾：**
我们是在构建一棵二叉树，每次合并两个节点（或子树）都会产生一个非叶子节点，其成本是左子树最大叶子 * 右子树最大叶子。我们的目标是总成本最小。

**关键观察 (为什么栈能行？)：**
想象一下，我们有一排叶子节点 `[a, b, c, d, ...]`。
一个关键点是：**一个叶子节点 `x` 最终总是会跟它左边的一个“代表性叶子”和右边的一个“代表性叶子”发生联系，形成一个非叶子节点。** 我们希望当 `x` 参与乘法时，它旁边的那个数尽可能小。

特别是，**如果一个较小的数 `m` 被夹在两个较大的数 `L` 和 `R` 中间（即 `L > m` 且 `R > m`），那么 `m` 迟早要和 `L` 或 `R` (或者它们所代表的子树中的最大叶子) 之一配对。为了让 `m` 贡献的成本尽可能小，它应该优先和 `min(L, R)` 配对。** 一旦 `m` 配对了，它产生的这部分成本就固定了，它也“功成身退”了。

单调栈就是帮我们巧妙地找到并处理这种“小数字被大数字夹击”的情况。

**算法步骤 (使用单调递减栈):**

让我们把这个过程想象成数字在一个特殊的“处理区”（栈）中排队：

1.  **初始化一个空栈 `stk`**: 这个栈用来存放那些暂时还未最终配对的叶子节点的值。我们希望维护栈内元素从栈底到栈顶是**单调递减**的（栈底的数最大，栈顶的数最小）。
2.  **初始化总成本 `ans = 0`**: 用来累计所有非叶子节点的成本。
3.  **遍历数组 `arr` 中的每个数 `num` (当前要处理的叶子)**:
    *   **循环检查栈顶元素**: 只要栈不为空，并且栈顶的叶子 `stk.top()` **小于或等于** 当前数 `num`：
        *   **为什么要出栈？** 栈顶的这个叶子 (`stk.top()`, 我们叫它 `leaf_to_process`) 现在遇到了一个比它大或相等的数 `num` (在它的右边)。同时，由于栈的单调递减性，`leaf_to_process` 左边的数 (即栈里在它下面的那个数，如果存在的话) 也比它大。
        *   `leaf_to_process` 正好处在一个“山谷”的位置，或者说它是一个局部的最小值，被左右两边的较大值“夹住”了。根据我们的贪心策略，这个 `leaf_to_process` 应该立即和它左右两个较大值中较小的那一个配对，以确定它所贡献的成本。
        *   **出栈操作**: `popped_leaf = stk.pop()`。这个 `popped_leaf` 就是我们要处理的叶子。
        *   **计算成本**:
            *   `right_partner_val = num` (当前数是右边的配对候选)。
            *   `left_partner_val = stk.empty() ? infinity : stk.top()` (如果弹出后栈空了，左边就没有伙伴，可以认为是个无穷大的值；否则，新的栈顶就是左边的配对候选)。
            *   成本增加: `ans += popped_leaf * min(left_partner_val, right_partner_val)`。
                *   **注意**: 如果 `stk.empty()` 为真（即 `popped_leaf` 是栈中最后一个元素，它左边没有其他元素了），那么它只能和 `num` 配对，成本是 `popped_leaf * num`。更严谨的写法是，`min` 的一个参数如果是 `infinity`，自然会取另一个。所以 `ans += popped_leaf * (stk.empty() ? num : min(stk.top(), num))` 是等价的。
        *   这个 `popped_leaf` 处理完毕，它的成本贡献已经加入 `ans`。继续循环，看新的栈顶是否也满足小于等于 `num` 的条件。
    *   **压入当前数**: 当循环结束（即栈为空，或者栈顶元素大于 `num`），说明当前数 `num` 找到了它在栈中合适的位置（它比栈顶小，或者栈是空的）。
        *   将 `num` 压入栈中: `stk.push(num)`。

4.  **数组遍历完毕后，处理栈中剩余的元素**:
    *   此时栈中可能还剩下一些叶子，它们从栈底到栈顶是严格单调递减的 (例如，栈底是较大的值，栈顶是较小的值，像 `[大, 中, 小]`)。
    *   这些剩下的叶子也需要两两配对形成更大的结构。
    *   只要栈中元素数量多于一个：
        *   `popped_leaf = stk.pop()` (弹出栈顶较小的那个)。
        *   它将与新的栈顶元素 `stk.top()` (即它在栈中的前一个、也是值更大的元素) 合并。
        *   成本增加：`ans += popped_leaf * stk.top()`。
    *   重复此过程，直到栈中只剩下一个元素（这个元素通常是原始数组中值最大的叶子之一，它作为根的一部分，不再需要与其它叶子去计算这种“内部节点”的成本了）。

**为什么这个贪心是对的？ (再通俗点)**
这个栈的操作确保了：任何一个叶子 `x`，当它因为一个比它大或相等的叶子 `y` (从右边过来，即当前处理的 `num`) 而被迫出栈时，`x` 就在它左边的栈内叶子 (也比 `x` 大，因为栈是单调递减的) 和 `y` 之间找到了一个“局部最优”的配对。它和左右两者中较小的那个配对，使得 `x` 参与的这次乘积最小。一旦这个成本加上 `ans`，`x` 就完成了它的使命（作为较小叶子参与构建一个非叶节点）。这个局部最优决策链最终导向全局最优。

**超详细例子：`arr = [6, 2, 4]`**

*   **初始状态**: `stk = []` (空栈), `ans = 0`

*   **1. 处理 `num = 6`**:
    *   栈为空。
    *   将 `6` 压入栈。 `stk = [6]`. `ans = 0`.

*   **2. 处理 `num = 2`**:
    *   栈不为空。栈顶 `stk.top() = 6`。当前 `num = 2`。
    *   检查循环条件: `stk.top() (6) <= num (2)` 不成立 (因为 `6 > 2`)。
    *   循环不执行。
    *   将 `2` 压入栈。 `stk = [6, 2]` (栈底是6，栈顶是2). `ans = 0`.

*   **3. 处理 `num = 4`**:
    *   栈不为空。栈顶 `stk.top() = 2`。当前 `num = 4`。
    *   **进入循环检查**: `stk.top() (2) <= num (4)` 成立！
        *   `popped_leaf = stk.pop() = 2`。栈现在是 `stk = [6]`.
        *   `right_partner_val = num = 4`.
        *   `left_partner_val = stk.top() = 6` (因为栈不为空，新的栈顶是6)。
        *   成本增加: `ans += popped_leaf * min(left_partner_val, right_partner_val) = 2 * min(6, 4) = 2 * 4 = 8`.
        *   现在 `ans = 8`.
    *   栈不为空。栈顶 `stk.top() = 6`。当前 `num = 4` (继续用外层的 `num` 进行比较)。
    *   **再次检查循环条件**: `stk.top() (6) <= num (4)` 不成立 (因为 `6 > 4`)。
    *   循环结束。
    *   将 `4` (当前 `num`) 压入栈。 `stk = [6, 4]` (栈底是6, 栈顶是4). `ans = 8`.

*   **数组遍历完毕！** `ans = 8`.

*   **4. 处理栈中剩余的元素**: `stk = [6, 4]`.
    *   栈中元素数量 `2 > 1`。
        *   `popped_leaf = stk.pop() = 4`。栈现在是 `stk = [6]`.
        *   成本增加: `ans += popped_leaf * stk.top() = 4 * 6 = 24`.
        *   现在 `ans = 8 + 24 = 32`.
    *   栈中元素数量 `1` 不大于 `1`。循环结束。

*   **最终答案**: `32`.

**再看一个例子 `[6, 2, 4, 5, 3]`** (快速过一遍，注意 `popped_leaf` 的使用)

1.  `stk = []`, `ans = 0`
2.  `num = 6`: `stk = [6]`
3.  `num = 2`: `stk = [6, 2]`
4.  `num = 4`:
    *   `stk.top()=2 <= 4`. Pop `2` (`popped_leaf=2`). `left=6`, `right=4`. `ans += 2 * min(6,4) = 2*4 = 8`. `stk=[6]`.
    *   `stk.top()=6 > 4`. Push `4`. `stk = [6, 4]`. (`ans=8`)
5.  `num = 5`:
    *   `stk.top()=4 <= 5`. Pop `4` (`popped_leaf=4`). `left=6`, `right=5`. `ans += 4 * min(6,5) = 4*5 = 20`. (Total `ans = 8+20=28`). `stk=[6]`.
    *   `stk.top()=6 > 5`. Push `5`. `stk = [6, 5]`. (`ans=28`)
6.  `num = 3`:
    *   `stk.top()=5 > 3`. Push `3`. `stk = [6, 5, 3]`. (`ans=28`)
7.  遍历结束。`stk = [6, 5, 3]`. `ans = 28`.
    *   Stack has `>1` elements. Pop `3` (`popped_leaf=3`). `stk.top()=5`. `ans += 3 * 5 = 15`. (Total `ans = 28+15=43`). `stk=[6,5]`.
    *   Stack has `>1` elements. Pop `5` (`popped_leaf=5`). `stk.top()=6`. `ans += 5 * 6 = 30`. (Total `ans = 43+30=73`). `stk=[6]`.
    *   Stack has `1` element. Stop.

最终答案: `73`.

这个单调栈解法非常精妙，它通过维护一个单调序列，确保了每当一个元素被“处理”时，都是在它能找到的“最佳时机”（即与左右两侧中较小者结合），从而一步步累加得到全局最优解。

### 4. 总结解法通用技巧

*   **区间DP的“思维路径”**:
    1.  **识别特征**: 数组/序列，求最优值，操作涉及子区间合并/划分。
    2.  **状态定义**: `dp[i][j]` 通常表示处理区间 `[i, j]` 的最优解。
    3.  **思考最后一步**: 区间 `[i, j]` 的解是如何由更小的子区间得到的？通常是枚举一个分割点 `k`。
    4.  **写出转移方程**: `dp[i][j] = min/max (dp[i][k] + dp[k+1][j] + cost_of_merging_k)`
    5.  **确定边界/初始条件**: `dp[i][i]` 通常是0或元素本身的值。
    6.  **确定遍历顺序**: 通常按区间长度从小到大，或 `i` 从大到小，`j` 从小到大。
    *   **关键词 + 触发**: “连续区间 + 最优值 + 分割点” => 区间DP。

*   **单调栈的“思维路径”**:
    1.  **识别特征**: 寻找每个元素左/右第一个更大/更小的元素；或者问题涉及元素的消除，且消除顺序和代价与相邻元素有关。
    2.  **栈的单调性**: 决定是单调递增栈还是递减栈。这取决于你想在遇到什么情况时处理栈顶元素。
        *   递减栈：当新元素 `x` 比栈顶大时，栈顶元素出栈。适用于找右边第一个比它大的。
        *   递增栈：当新元素 `x` 比栈顶小时，栈顶元素出栈。适用于找右边第一个比它小的。
    3.  **处理出栈元素**: 当一个元素 `top` 从栈中弹出时，通常意味着它找到了它在某个方向上的“界限”（比如新来的元素 `x`，或者 `x` 之前的栈内元素）。此时计算 `top` 相关的贡献。
    4.  **处理栈内剩余元素**: 遍历结束后，栈内可能还有元素，需要按特定规则清空并计算贡献。
    *   **关键词 + 触发**: “每个元素的左右最近影响者”、“消除序列”、“局部瓶颈” => 单调栈。

对于本题，DP 是一个比较通用的思路，而单调栈则是针对这类“寻找最优合并顺序，且合并代价与局部最大/最小值相关”问题的特化高效解法。

### 5. 延伸：相似题目练练手

1.  **LeetCode 96. 不同的二叉搜索树 (Unique Binary Search Trees)**
    *   **链接**: [https://leetcode.cn/problems/unique-binary-search-trees/](https://leetcode.cn/problems/unique-binary-search-trees/)
    *   **相似点**: 给定 `n` 个节点，问能构成多少种不同的二叉搜索树。这也是一个典型的区间DP（或者说卡特兰数应用）。
    *   **应用技巧**: `dp[i]` 表示用 `i` 个节点能构成的不同二叉搜索树的数量。枚举根节点，则左子树有 `j` 个节点，右子树有 `i-1-j` 个节点。`dp[i] = sum(dp[j] * dp[i-1-j])`。这和我们题目中枚举分割点 `k`，将问题分解为左右两部分非常相似。

2.  **LeetCode 312. 戳气球 (Burst Balloons)**
    *   **链接**: [https://leetcode.cn/problems/burst-balloons/](https://leetcode.cn/problems/burst-balloons/)
    *   **相似点**: 给定一个数组代表气球分数，每次戳破一个气球 `i`，得到 `nums[left] * nums[i] * nums[right]` 的分数。求最大总分数。
    *   **应用技巧**: 这是区间DP的经典题目。`dp[i][j]` 表示戳破区间 `(i, j)` 内所有气球（不包括 `i` 和 `j`）能得到的最大分数。关键在于“逆向思考”：最后戳破哪个气球 `k` 在区间 `(i, j)` 内？如果 `k` 是最后被戳的，那么它的左右边界就是 `i` 和 `j`。
        `dp[i][j] = max(dp[i][k] + dp[k][j] + nums[i] * nums[k] * nums[j])` for `k` in `(i, j)`.
        这与本题中 `dp[i][j] = min(dp[i][k] + dp[k+1][j] + cost)` 的结构非常像，都是通过枚举最后一个操作（分割点或最后戳的气球）来划分区间。

3.  **LeetCode 84. 柱状图中最大的矩形 (Largest Rectangle in Histogram)**
    *   **链接**: [https://leetcode.cn/problems/largest-rectangle-in-histogram/](https://leetcode.cn/problems/largest-rectangle-in-histogram/)
    *   **相似点**: 寻找以每个柱子为高度的最大矩形面积。这需要找到每个柱子左右两边第一个比它矮的柱子。
    *   **应用技巧**: 这是单调栈的经典应用。维护一个单调递增栈（存下标）。当遇到一个柱子 `h[i]` 比栈顶柱子矮时，说明栈顶柱子找到了它的右边界（就是 `i`），它的左边界是栈顶下面的那个柱子。可以计算以栈顶柱子为高的矩形面积。
        这与本题单调栈解法中，当一个元素 `mid` 出栈时，它被新元素 `num` (右边界) 和新栈顶 (左边界) “夹住”并计算贡献的思路是相通的。

这些题目虽然具体场景不同，但底层的“区间划分”、“寻找最优子结构”、“利用单调性加速查找”等思想是触类旁通的。多练习，就能培养出这种“题感”啦！

希望这篇“教学式”的文章能帮你更好地理解这类问题！学习算法就像交朋友，多处处，多聊聊，就熟悉了！😄
