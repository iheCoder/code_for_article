## 上下文工程：从“炼金术”到“方法论”，构建高确定性AI系统的核心引擎



在大型语言模型（LLM）的实践中，我们常常陷入一种矛盾的狂热：一方面惊叹于它涌现出的强大能力，另一方面又对其输出的“不确定性”感到沮 fous。我们像中世纪的炼金术士，反复调试提示词（Prompt），试图找到那组能点石成金的“咒语”。

然而，真正构建企业级、高可靠性的AI应用，靠的绝不是“炼金术”，而是一套严谨的“方法论”。**上下文工程（Context Engineering）**正是这套方法论的核心。它将我们的角色从“提示词魔术师”转变为“信息架构师”，其核心目标只有一个：**通过系统化地设计、输送和管理信息，最大限度地降低LLM推理的“认知负荷”，从而将不确定性转化为高确定性的输出。**

这篇文章将深入探讨上下文工程的本质，并为你铺开一条从理论到实践的清晰落地路径。

## 第 1 章 定义与边界：上下文工程究竟是什么、不是什么

### 定义

**上下文工程（Context Engineering）**：

在给定任务与预算下，**选择、组织并按时送达**对模型最关键的**信息与工具**，让它**可核验、可执行、稳定**地完成工作。

> 三个动词是核心：**选择**（检索/筛掉噪声）、**组织**（压缩/排版/设定输出契约）、**按时送达**（在合适的步骤喂入，并在需要时调用工具）。

> 其它扩展维度（权限、评测、成本等）是落地时的配套要求



### 为什么需要这门“工程”

1. 模型并不“过目不忘”。长上下文会出现**位置偏置**：对开头、结尾更敏感，中间最容易被忽略。把 100 页原文全塞进去，只会让关键信息**被噪声埋没**。

2. 企业问题强调**可核验与合规**：答案需要能指向证据，还要遵守权限边界。

3. **成本与延迟**是硬约束：token、Rerank、调用链都要钱、要时间。

   上下文工程解决的正是这三件事：**控噪声、保证据、守预算**。

### 与其它路线的边界（知道“不是什么”更重要）

- **RAG（检索增强生成）**：上下文工程的“骨干肌肉”。当你需要**最新/专有知识 + 可核验引用 + 权限**时，它是默认选项。
- **长上下文（Long Context）**：适合**单文档通读/风格保持**的场景，但别把它当“万能桶”；仍需**压缩与布局**避免中段丢失。
- **微调（Fine-tuning）**：当任务**格式稳定/风格固定/术语统一**，用小中模型微调可提稳健性与单位成本；但**知识频繁更新或需要证据**时，优先上下文工程，再视需要叠加微调。

### 三条设计铁律

#### 最小必要上下文（Least Necessary Context）

- **做法**：只放“对这次决策有直接贡献”的片段；其余一律留在检索层。

- **为什么**：上下文是“显存”，不是仓库。多一个无关段落，就多一份注意力被分走的可能。

- **例子**：问“**退货邮费谁承担？**”



- ✅ 放：退货条款里“**退货邮费由商家承担**”的句子 + 生效日期。
- ❌ 不放：运费险定义、仓库地址、与退货无关的“换货流程”。



#### 证据可核验（Citations First-Class）

- **做法**：答案必须能回指到**原文片段**或**外部工具的可追溯结果**；在生成前后做**引用对齐检查**。
- **为什么**：这是“可信”的唯一硬边界，能防止“看似对但无出处”的幻觉。
- **例子**：回答“退款时效 7 天”，旁边标注【来源：售后政策 §3.2，第 2 句】；若证据缺失则**拒答**或提示需要人工/外部系统确认。



#### 显式契约：结构化输出 + 工具调用

- **做法**：用 **JSON Schema** 限定输出；需要行动时走**函数/工具调用**（查库、跑 SQL、生成报表），模型只给参数。

- **为什么**：自由文本不可控、难重试；契约化让**自动化**成为可能。

- **例子**：

    - Schema：{"policy":"string","deadline":"date","is_refundable":"boolean","citations":[...]}
    - 如果要查“用户是否在可退期”，让模型调用 check_return_window(order_id)，而不是让它**猜**。



### 关键构件小词典

- **切块（Chunking）**：把文档按**语义/结构**切成小段，便于检索与引用。表格、代码要用**专门切块器**。

- **召回（Recall）**：从海量语料挑出**可能相关**的片段，拿到一个候选集合（Top-K）。

- **重排（Rerank）**：对候选集合逐段“深入比对”，把**看起来像**但**其实不相关**的剔除。

- **硬负例（Hard Negative）**：**表面相似但内容无关**的迷惑片段，会强烈干扰模型判断。

    - **生动例子**：
        - 问题：*“退货邮费谁承担？”*
        - 片段 A（正例）：*“非质量问题退货，****退货运费由消费者承担\****。”*
        - 片段 B（**硬负例**）：*“****运费险\****由保险公司承担，理赔需在 48 小时内申请。”*
        - 它们都出现“运费/承担”，但 B 讨论的是**保险赔付**，不是**退货运费**。把 B 也塞进上下文，模型极易得出“商家或保险公司承担”的错误结论。



- **HyDE**：让模型先写一段**“假答案的短文”**，拿它去向量检索，提高“问题太短/没标注”场景下的召回质量。

- **位置偏置（Lost-in-the-Middle）**：长上下文里，中间的信息最容易“糊掉”；把关键信息前置是常用对策。

- **结构化输出（Structured Outputs）**：用 Schema 让答案“对齐可解析格式”。

- **函数/工具调用（Function Calling / Tools）**：把“要做事”的部分交给外部系统执行；模型只负责“**决定做什么**”与“**填参数**”。

- **GraphRAG**：把文本抽成**实体-关系图**，先做“社区级摘要”，再结合原文检索，适合**多实体/多跳**问题。

- **Prompt Caching**：平台对**相同前缀内容**（系统指令/Schema/工具说明/示例）做缓存，重复使用更快更便宜——所以要把**稳定内容**放在提示的**最前**。

### 常见反模式

#### 反模式 A “把 Top-K 一味拉大”

- **现象**：从 10 拉到 50、100，觉得“多多益善”。

- **为什么坏**：K 变大，**硬负例**的比例陡增；模型注意力被分走，答案变得**似是而非**。

- **怎么改**：



1. 先**多路召回**（向量 + 关键词 + 多查询/HyDE），得到 30–50 个**候选**；
2. 用 **Rerank** 把候选压到 **Top-5/Top-8**；
3. 给每段证据打**一致性分**，低于阈值就不带进上下文。



- **例子**：问“退货邮费谁承担？”



- 拉 50 段：出现“运费险条款”“发货运费”“邮寄地址”等**硬负例**；
- 用 Rerank 压到 5 段：只剩“退货条款 + 生效时间 + 例外情况”，答案稳定。



#### 反模式 B｜“只用向量检索”

- **现象**：把 BM25（关键词）全关掉。
- **为什么坏**：**编号、术语、公式、代码符号**对语义向量并不敏感，容易漏召回。
- **怎么改**：**混合检索**（向量 + BM25）+ **融合排序**（如 RRF），保证“语义与字面”都照顾到。
- **例子**：问“**表 A 第 12 条**怎么规定？”只靠向量，很可能错过“第 12 条”的精确匹配。



#### 反模式 C｜“能塞就塞，整本手册进上下文”

- **现象**：害怕漏信息，把整篇放进去。

- **为什么坏**：触发**位置偏置**，中间信息易丢；同时**成本陡增**。

- **怎么改**：



- **预算化压缩**：先抽关键句；
- **布局优化**：把关键信息放在前部；
- **引用对齐**：保留原文片段 ID，答案里标注来源。



- **例子**：把“退货流程图”整页贴进去不如摘出“承运人遴选不影响邮费承担方”的一句关键话。



#### 反模式 D｜“自由文本输出，一把梭”

- **现象**：让模型写“自然语言长段落”，下游系统读不懂。

- **为什么坏**：不可解析、不可重试、不可审计。

- **怎么改**：**JSON Schema** + **函数调用**。

- **例子**：



- ❌ “您可以退货，邮费我司承担。”
- ✅ {"is_refundable":true,"postage_payer":"merchant","policy":"售后政策§3.2","citations":[{"doc":"policy_v7","sec":"3.2","sent":2}]}



#### 反模式 E｜“权限后补”

- **现象**：先检索、后过滤。
- **为什么坏**：即便最后没展示，**越权检索**也可能在日志里留下痕迹。
- **怎么改**：**检索前**按租户/角色做**索引级过滤**；**检索后**再做结果级过滤，双保险。



#### 反模式 F｜“不设预算，不看延迟”

- **现象**：为了“更准”，一路加模型、加上下文、加外部工具。
- **为什么坏**：等你“准”的时候，用户已经走了。
- **怎么改**：在 PRD 里就定下**P95 延迟/单位成本**，通过**压缩、缓存、模型级联**守住。



### 一个“带数字”的迷你案例（从检索到答案，走一遍）

**问题**：*“7 天无理由退货，邮费谁承担？”*（期望 2 秒内答复，必须给出处）



**Step 1｜召回（30–50 条）**

- 向量检索：召回 30 条；
- 关键词（BM25）：“退货”“邮费”“承担”精确匹配：召回 25 条；
- HyDE 生成人类可读“假答案”，再向量检索：新增 10 条；
- 合并去重得到 **50 条候选**，先按**权限**过滤掉跨租户内容。



**Step 2｜重排（Top-50 → Top-6）**

- 用 cross-encoder/Rerank 逐段比对“问句 ↔ 片段”；
- 设**一致性阈值 0.6**，低于阈值剔除；
- 结果保留 **6 段**：包括“退货条款 §3.2”、“例外情况（大件/生鲜）”、“生效时间”。



**Step 3｜压缩与布局（塞进 800 tokens 预算）**

- LongLLMLingua 提取每段**关键句**并去重；
- 把“**承担方**与**例外**”放在上下文**最前**；
- 在每段后保留 {doc_id, section, sentence_id} 作为**引用锚点**。



**Step 4｜编排与执行**

- System 提示写清：要**JSON 输出** + **必须引用**；
- 如果用户附了订单号，触发 check_return_window(order_id) 工具，确认是否仍在 7 天内；
- 模型合成答案，填入 postage_payer="consumer|merchant|platform|unknown"，并附引用列表。



**Step 5｜答案（机器可读 + 人能懂）**

```
{
  "is_refundable": true,
  "postage_payer": "consumer",
  "policy": "售后政策 v7 §3.2",
  "exceptions": ["质量问题由商家承担", "生鲜不适用7日"],
  "citations": [
    {"doc":"policy_v7","sec":"3.2","sent":2},
    {"doc":"policy_v7","sec":"3.5","sent":1}
  ]
}
```

> 展示给用户的自然语言可由这个 JSON 二次渲染；一旦政策更新，只需重建索引即可，无需改模型。



### 小结（把这一章落成“评审清单”）

- **定义**：选择 / 组织 / 按时送达 **关键信息与工具**——为**可核验、可执行、可控**服务。

- **铁律**：最小必要上下文｜证据可核验｜结构化输出 + 工具调用。

- **反模式**：Top-K 盲目增大｜只用向量不混检｜整本塞上下文｜自由文本无契约｜权限后补｜不设预算。

- **会做的三件事**：



1. 先把**证据**做对（混合召回 + 重排 + 压缩 + 布局）；
2. 再把**输出**做稳（Schema + 函数调用 + 引用对齐）；
3. 最后把**成本/延迟/权限**做实（预算 + 缓存 + 双层 ACL）。



## 第 2 章 分层架构与数据流：把上下文工程落成可复用的流水线

*——RAG 是骨干；检索→重排→压缩→编排→行动→观测与安全，一条跑通的工程链*



> 章导读：这一章不“堆知识点”，而是把上下文工程如何被**真正实现**讲清楚：一张**总览图**、一条**数据流**、五个**工程层**。其中把不那么家喻户晓的概念（LLMLingua/LongLLMLingua、ReAct、Toolformer、GraphRAG、HyDE、结构化输出/函数调用、Prompt Caching）逐个解释到能上手的程度。最后给一份**生产级强基线配方**（含参数与可操作检查单）。



## **2.0 总览图：系统是怎么跑起来的（先看图，再走路）**



![RAG_pipeline](./上下文工程：从“炼金术”到“方法论”，构建高确定性AI系统的核心引擎.assets/RAG_pipeline-5607825-5607830.png)

**一句话把数据流说透**：

**找对材料（L1/L2）→把材料变成“可被模型可靠吸收”的输入（L3）→让模型“按契约说话并能动手”（L4）→全程可观测、可回滚、可控成本（L5）**。RAG 是**骨干肌肉**，L3 是**消化与摆盘**，L4 是**大脑带着手脚去干事**，L5 是**神经系统与免疫系统**。





### L1｜摄取与索引（把料备对：可检索、可授权、可引用）



要点

- **清洗/切块/脱敏/加元数据**：切块不是均匀截断，而是**语义/结构感知**（段落、标题层级、表格单元、代码块）。每个块附：{title, section, time, doc_id, chunk_id, ACL}。
- **混合索引**：**向量库**负责语义相似，**BM25**负责编号/术语/符号等精确匹配。两条索引并存，为后续融合排序打基础。



常见坑

- *“只做向量”* → 漏召回专业编号/条款；
- *“切块太粗/太细”* → 粗了不准，细了上下文碎裂。**经验**：以“一个问句能被完整回答的最小段”为目标，表格/代码用专用切块器。



### L2｜召回与证据甄别（RAG 的骨干肌肉）

#### 多路召回（Recall）

- **向量检索**：拿到语义相似的一批候选（Top-N）。

- **关键词检索（BM25）**：兜底**编号/术语/符号**类精确匹配。

- **多查询（Multi-Query）**：把一个问句改写成多种表达（同义/扩展）以扩大覆盖面。

- **HyDE（Hypothetical Document Embeddings）是什么？**

  > 让模型**先写一段“可能答案的短文”**（假文档），把它向量化去检索真文档。**用途**：冷启动/短问句/信息稀疏时，能更好“对上味儿”。





权限预过滤

- 在“提候选”的这一刻就按租户/角色进行**索引级过滤**；之后再做**结果级过滤**，双层兜底。



#### 语义重排（Rerank）

- **是什么**：用更强的句对模型对“问题 ↔ 候选段落”逐段打分，把“**看起来像但不相关**”的**硬负例**剔除。
- **为什么**：Top-N 出来的候选里总混着“预感很对却答非所问”的段落；**不重排就带毒**。
- **怎么做**：Top-N（30–50）→ Rerank → **Top-k（5–8）**；设置**一致性阈值**，不够就拒答/降级。



> **硬负例再解释（快速复习）**：

> 问“退货邮费谁承担？”——“运费险理赔规则”语义表面接近，但并不回答“退货运费”这个问题。把它带进上下文，模型很容易“张冠李戴”。**Rerank 的使命就是把这种“看起来像”的段落踢出去**。



### L3｜上下文构造：压缩、布局与编排（把料做成菜，易消化）

#### 预算化压缩

- **它是什么**：一种**以 token 预算为硬约束**的压缩方法，按重要性保留关键句/关键词/实体与数字，尽量不损失“能回答问题”的信息。

- **为什么不是“普通摘要”**：普通摘要追求可读性；**预算化压缩**追求“**在 X 个 token 里，最大化可用信息密度**”。

- **怎么用**：

    1. 给定预算（比如 800 tokens），
    2. 对 Top-k 证据段逐段压缩，
    3. 合并去重，
    4. 保留**引用锚点**（doc/chunk/sent_id）。



- **收益**：降延迟/降成本，同时**缓解长上下文的“中段遗失”（位置偏置）**。

- **形象比喻**：不是“写读书笔记”，而是“给开卷考试做**可查要点卡**”。



#### 位置布局优化（为什么“放哪儿”很重要）

- **位置偏置**：模型对**开头/结尾**更敏感，中间更易“糊”。
- **策略**：把**答案关键句**、**限制条件/例外**、**数字/日期**放在上下文**前部**；把“背景描述/次要论据”往后排。



#### 编排为“可执行提示”

- **系统指令**：角色、语气、合规边界（例如“必须给出 JSON，若无证据则拒答”）。
- **证据块**：压缩后的段落 + 引用锚点。
- **输出契约**：**JSON Schema** 定义字段、类型、约束；
- **工具清单**：列出可调用的函数（名称、参数、返回结构、权限说明）。



### L4｜模型编排与行动：让答案“对齐 + 能干事”

#### 结构化输出（Structured Outputs）

- **是什么**：让模型严格按你提供的 **JSON Schema** 输出，**可解析、可重试、可校验**。
- **为什么**：自由文本好看，但**系统接不住**；Schema 让上下游对齐、错误可定位。



#### 函数/工具调用（Function Calling / Tools）

- **是什么**：模型不“自己做事”，它**提出要做的事与参数**；系统去执行（查库/跑 SQL/生成报表/调用搜索等），结果再回给模型。
- **好处**：可审计、可限权、可复现，避免“模型瞎编执行结果”。



#### ReAct & Toolformer（两种常被提到、但容易被说玄学的范式）

- **ReAct（Reason + Act）**：**计划—行动—观察—再计划**的循环。模型先制定小计划（如“先查是否在 7 天内，再查邮费条款”），调用工具拿到结果，再继续下一步。
- **Toolformer**：让模型在预训练式数据上**学会何时调用哪个工具**，像“带插件的大脑”。
- **工程落地怎么取舍**：
    - 需求**步骤清晰**、可枚举 → 直接**函数调用 + 明确调用顺序**；
    - 需求**探索性强/步骤动态** → 用 ReAct 做**轻规划**，但在生产要**限制可调用工具与参数范围**。



#### 引用对齐与一致性检查

生成完毕，逐条核对答案中的论断是否能在**证据块**里找到支撑；缺失则降级/拒答/提示“需人工/需工具进一步确认”。



### L5｜观测、安全与成本工程（跑得快也要看得见）

**双层权限**



- **检索前**按 ACL 做索引/查询过滤；**检索后**再做结果级过滤，防越权泄露。



**可观测**

- 为每次回答记录**查询→召回→重排→压缩→编排→输出/调用→引用**的 Trace；
- 关键指标：**Recall@k、Rerank 提升Δ、忠实度、引用一致率、Schema 合规率、P95 延迟、单位成本、拒答率**。



**成本与 SLO**

- **Prompt/Context Caching**：把**稳定前缀**（系统指令/Schema/工具说明/示例）放在提示最前，提升缓存命中，显著降时延与成本。
- **模型级联**：轻模型做召回/重排，重模型做综合；
- **熔断与回滚**：指标异常自动退回“安全基线”（例如禁用压缩或禁用某个工具调用路径）。



### 生产级“强基线配方”（能直接照着搭）

> 目标：以**稳定正确/低延迟/可核验**为第一优先，先把“骨干肌肉”练强，再加花活。



**输入**：问句 Q（可含业务上下文/用户身份），预算 800–1,200 tokens，P95 ≤ 2s（示例），必须输出 JSON。

**Step-by-Step**



1. **摄取与索引（离线）**



- 语义/结构切块：段落 120–300 token；表格按行/单元格；代码按函数/文件块。
- 元数据：{doc_id, chunk_id, title, section, time, acl}。
- 建双索引：向量库（HNSW/IVF 等） + BM25。



2. **召回（在线）**



- 向量 Top-30 ⊕ 关键词 Top-30 ⊕ **HyDE** Top-10 → 合并去重 ≈ **Top-50**。
- 先做**索引级权限过滤**（租户/角色）。



3. **语义重排**



- Cross-Encoder / Rerank → **Top-k=5~8**，并为每段生成**一致性分**；低于阈值（如 0.6）剔除。
- **注意**：不要“Top-k 盲目拉大”，硬负例的比例会随 k 上升而上升（上一章已用例子解释）。



4. **预算化压缩与布局**



- LongLLMLingua：把 Top-k 压到预算内；保留数字、日期、否定词与边界条件。
- 布局：**关键句前置**，背景次序靠后。
- 为每段保留引用锚点 {doc/chunk/sent}。



5. **编排提示**



- System：角色/合规/必须 JSON/必须引用。
- Context：压缩证据块（带锚点）。
- Tools：允许调用的函数（白名单与参数约束）。
- Output：**JSON Schema**（严格模式）。



6. **生成与行动**



- 结构化输出 → 若需查实时信息（如“是否仍在 7 天内”），调用 check_return_window(order_id)；
- 合并工具返回，第二次生成最终 JSON。



7. **引用对齐与校验**



- 检查 JSON 中的每个关键断言是否在证据块中找到对应句子；缺失则降级/拒答。



8. **观测与缓存**



- 记录全链路 Trace；**开启 Prompt/Context Caching**；
- 看板监控：ITR、忠实度、引用一致率、P95、单位成本、缓存命中率、拒答率。





**落地检查单（做完以上 8 步逐条自查）**



- 同问句多次调用，Top-k 组成稳定、答案可复现
- JSON 严格符合 Schema，异常可重试
- 每条答案都有可回溯引用；缺证据时系统会拒答
- P95 与单位成本在预算内；缓存命中率达标
- 权限在检索前/后均生效；越权检索零容忍
- 可一键回滚到“无压缩/无工具调用”的安全基线



### 概念速通卡（本章出现的“容易陌生”的名词，30 秒回忆）

- **HyDE**：先写“假答案短文”，拿它做向量检索——冷启动时救命的召回放大器。
- **Rerank**：用强模型逐段打分，把**硬负例**踢出去（Top-N→Top-k）。
- **硬负例**：表面相似、实则不答题的段落（运费险≠退货邮费）。
- **LLMLingua/LongLLMLingua**：**按预算**压缩证据，保关键句与实体，兼顾速度/成本/正确性。
- **结构化输出**：按 **JSON Schema** 输出，机器能读、能重试、能校验。
- **函数/工具调用**：模型只给“要做的事与参数”，系统去做，结果回填。
- **ReAct**：计划→行动→观察→再计划；步骤不固定的任务用它更稳。
- **Toolformer**：让模型学会**何时**调用**哪个**工具（更“本能”的工具选择）。
- **GraphRAG**：把文本变“实体-关系图”，做社区摘要+原文证据的混合检索，适合多实体多跳。
- **Prompt/Context Caching**：把**稳定前缀**放前面，平台自动缓存，延迟和成本一起下台阶。

### 小结（本章你真正带走的东西）

- 一条可执行的数据流：**L1 找对料 → L2 骨干肌肉（RAG）→ L3 做成菜（压缩/布局/编排）→ L4 大脑+手脚（结构化输出/函数调用/规划）→ L5 神经与免疫（观测/安全/成本）**。
- 把**陌生名词**讲到能用：LLMLingua/LongLLMLingua、HyDE、ReAct、Toolformer、GraphRAG、结构化输出、Prompt Caching。
- 一套**生产级强基线配方**：你可以直接照着搭，先把骨干肌肉练强，再追求更花的增强（比如 GraphRAG、智能规划、多工具协同）。



## 结语



从“大海捞针”式的提示词调试，到构建一个精密的、自动化的信息处理流水线——这就是上下文工程带来的认知飞跃。它虽然复杂，但它将AI应用开发从一门“艺术”变成了一门真正的“工程科学”。

放弃寻找“完美提示词”的幻想吧。真正的护城河，在于你如何为你的大模型构建一个无与伦比的、高效的信息供给系统。这，就是上下文工程的全部意义所在，也是通往通用、可靠人工智能的必由之路。