# MemOS：面向内存增强型大语言模型的操作系统的深度技术解析与实践路径



大语言模型（LLM）的迅速发展为通用人工智能（AGI）的实现奠定了基础，但当前LLM在**记忆**方面的架构仍然存在重大缺陷 。传统LLM主要依赖模型参数中隐式存储的**参数记忆**（parametric memory），以及推理时临时的**激活记忆**（activation memory），即上下文窗口内的短期状态 。这种设计导致模型**缺乏长期记忆和结构化记忆管理**，难以在多轮对话中保持一致，也无法随时间持续更新知识 。虽然近年来出现了**检索增强生成**（RAG）等方法，通过外部知识库以纯文本形式扩展模型上下文 ， **，但RAG只是**一种无状态的补丁方案**——缺乏对引入记忆的生命周期管理，也无法与模型内部表示深度融合 。例如，RAG返回的文本片段不会被模型“记住”或更新，且难以支持跨模态知识和多用户场景 。



**MemOS**（Memory Operating System）正是在此背景下提出的一种全新框架，被称为“**内存操作系统**”。MemOS的核心思想是**将“记忆”提升为与算力同等重要的系统资源**，为LLM提供统一、结构化的长期记忆机制 。与以往仅依赖参数或上下文的方案不同，MemOS将**明文记忆**（plaintext, 外部可编辑知识）、**激活记忆**（模型运行时的隐藏状态）和**参数记忆**（模型权重中的知识）**统一纳入同一体系进行调度、融合、归档与权限管理** 。这一设计使得模型能够“**记住**”过去的交互、**适应**不断变化的新知识，并在多平台、多代理间**迁移**和重用经验，实现持续进化和自我更新 。



本文将对MemOS展开全面深入的调研。从学术和工程角度剖析其技术原理和架构，探讨为什么需要MemOS，以及它相较于传统RAG、LangChain记忆模块和MemGPT等方案的异同。我们也将收集**实际案例**（包括开源实验和潜在企业应用场景）来说明MemOS的作用，并分析其在**工程落地**时面临的挑战与机会（如性能、扩展性、隐私合规等），最后展望这种内存增强LLM架构的未来发展方向。





## MemOS 是什么？核心理念与背景对比

**MemOS**（Memory-Augmented Generation的操作系统）是为LLM设计的“**记忆管理操作系统**”，旨在填补当前LLM基础设施在记忆处理上的空白 。MemOS第一次将记忆提升为模型的**一等公民资源**，提供统一的**表示、组织和治理机制**来管理不同类型的记忆 。具体而言，MemOS引入了一个名为**MemCube**（记忆立方，或称记忆单元）的核心抽象，将各种记忆内容及其元数据封装起来，作为系统中标准化的记忆执行单元 。借助MemCube，MemOS可以在不同记忆类型之间进行跟踪、融合和迁移，并通过统一接口提供**结构化、可追踪**的记忆访问 。这一设计使LLM摆脱了仅能感知和生成的被动模式，转向能够**主动记忆、适应和成长**的新范式 。



与其他方案相比，MemOS有着鲜明的特点：



- **区别于RAG**：RAG在每次问答时检索外部文本注入模型上下文，但不具备对记忆的长期管理。相比之下，MemOS提供完整的**记忆生命周期管理**，包括记忆的生成、更新、版本控制和淘汰等，使知识可以随时间演化  。同时，MemOS支持**多模态**记忆融合（例如文本、图像等），而RAG主要限于纯文本检索 。可以说，MemOS并非仅在推理时拼接知识，而是**建立了一个可控、可演化的记忆基础设施**。
- **区别于LangChain Memory**：LangChain的记忆模块主要在应用层面保存对话历史或外部信息，以便在下次调用LLM时提供上下文 。它通过在对话开始时读取历史记忆增强输入，在对话结束后写入新记忆，赋予聊天机器人一定的持续对话能力 。然而，LangChain Memory并没有对记忆进行统一调度和治理的架构；**它更像开发者使用的工具**，通过简单的缓存、摘要或向量数据库，实现**短期对话续接**和**有限长程记忆** 。相比之下，MemOS是在模型系统层面引入记忆管理：它不仅存储对话历史，还管理模型的隐式状态和知识更新，具备**版本控制、权限管理**等完善机制  。简单来说，LangChain Memory解决“如何把上一次对话记下来供下次用”，而MemOS要解决的是“如何让模型像人一样拥有长期记忆，并能自主管理这些记忆”。
- **区别于MemGPT**：MemGPT是一种受操作系统虚拟内存启发的方法，核心是给LLM加入**分层内存**机制，在**主上下文**（相当于RAM）和**外部上下文**（相当于硬盘）之间智能换入换出数据，以突破上下文窗口限制  。MemGPT通过让LLM产生特殊的函数调用（如“中断”机制），在需要时将过去对话或文档片段从外部存储取回主上下文，从而实现几乎无限长度的对话或文档分析  。这使LLM能够记住之前会话的信息并在对话中**自主检索和更新上下文**  。**但MemGPT主要关注的是上下文扩展**的问题，即**如何在不增加模型上下文窗口的情况下，让模型“看”到更多内容**。MemOS则在更广义的系统架构上做文章：**除了上下文分页，MemOS还涵盖了模型知识的持续积累和治理**。MemGPT可以被视为在单个LLM代理内实现“虚拟内存”，让LLM自己调度内外存 ；而MemOS构建的是一个全面的**记忆操作系统**，包含内存调度、存储、权限、多代理协作等完整子系统  。换言之，MemGPT解决“LLM如何用类似操作系统内存管理的方法扩充上下文”，而MemOS解决“如何搭建一个让LLM拥有可管可控**长久记忆**的平台”，两者理念相通但着力点不同。
- **区别于Mem0等其他方案**：Mem0是2025年提出的一个**面向生产环境的记忆架构**，以**图结构的长期记忆**提升多轮对话连贯性，强调高效和可扩展 。Mem0通过动态抽取对话中的关键信息，构建结构化**图谱式记忆**，实现较以往RAG更高的对话一致性和效率  。在长期多会话对话基准LoCoMo上，Mem0表现出色：**对OpenAI方案在准确率上有26%的提升，95分位响应延迟降低91%，token成本节省90%以上** 。可见Mem0证明了**结构化长期记忆**对于对话系统的重要价值。然而，Mem0聚焦于**对话代理的记忆层**，强调个性化和图结构知识组织，被称为“个性化AI的记忆层” 。它支持**多层次记忆**（用户级、会话级、代理级）和**自适应个性化**等特性 。相比之下，MemOS的愿景更广：不仅用于对话，还希望支持知识的持续更新、跨任务迁移、多Agent协同等更普遍的智能体记忆需求  。**表面上看**，Mem0等可以看作是特定场景下的记忆解决方案，而MemOS试图建立一套**通用的记忆操作系统标准**，未来甚至发展出跨模型的记忆共享协议和去中心化的记忆交易市场  。在实现上，MemOS更强调**统一调度与治理**（例如提供MemGovernance权限系统、MemLifecycle版本管理等），这些在Mem0等方案中尚不完善 。





总的来说，MemOS代表了一种**范式转变**：从仅靠增大模型或上下文长度（扩展“暂时记忆”）的路径，转向通过一个**专门的记忆管理层**赋予模型**长期、可进化的记忆** 。这与早期一些人类记忆启发的尝试一脉相承（如Hippocampus模拟的**HippoRAG**、显式记忆网络**Memory$^3$等** **），但MemOS将这些想法提升到**系统框架**层面，使记忆成为LLM架构的有机组成部分。





## 为什么需要 MemOS？（痛点与差距）

引入MemOS的动机源于当前LLM在**长期记忆和适应性**方面存在的四大痛点 ：



1. **长期多轮对话缺失记忆**：现有LLM难以跨越有限的上下文窗口，在长对话中保留关键信息。用户可能在对话中提出偏好或约束，但几轮后模型即遗忘，导致回复前后不一致  。例如，一位用户在第5轮告诉助理预算是30万元，但在第15轮，模型可能已忘记此约束又推荐超预算的方案 。这种“对话失忆症”严重影响用户体验。MemOS通过在每轮对话后**提取关键信息**（如预算、偏好）存入**对话记忆单元**，并在推理时由MemScheduler检索相关片段注入上下文，确保语义状态持续**连贯**  。因此，MemOS能够弥补模型的短期记忆局限，让多轮对话像连续对话而非一次次重启。
2. **知识更新缓慢，缺乏演化**：大模型的知识主要来自训练语料，是**静态的**。现实世界知识不断演变，模型若不重新训练就无法反映最新信息。这既昂贵又有遗忘旧知识的风险（灾难性遗忘） 。而RAG虽然可以引入新文档，但对不同版本知识缺乏管理和验证，容易形成碎片化甚至冲突的外部知识集合 。MemOS将知识视为**动态的、受生命周期管控**的记忆。每条知识记忆都有生成、更新、融合、弃用等阶段属性 。例如，当出现新版医疗指南时，可通过MemStore发布为新的记忆块并标记为“可信来源”，MemOS会自动比对旧版，将过时知识归档，推理时优先使用新版本 。这样，模型无需重新训练即可**持续保持知识新鲜**，同时由于版本可控，也避免了盲目叠加新信息导致的不一致。
3. **个性化和多角色上下文缺乏**：当前LLM通常是**无状态**的，每次对话不记得用户是谁，也不区分不同身份的语气风格 。这使用户每次交互都要重复提供偏好，模型也难以维护稳定的人格或角色设定。MemOS在系统级支持**身份感知的记忆**和**基于角色的行为**。每个用户可以有独立的记忆空间，且一个账户下可包含多个角色，每个角色拥有自己的记忆子空间 。例如，一个用户既以“家长”身份与助理讨论家庭安排，又以“经理”身份处理工作任务。MemOS会分开存储两种角色的历史和偏好，在推理时**动态加载对应角色的记忆**，使助理的回答风格语气与角色匹配 。此外，长期互动中形成的**个人记忆单元**（如语言风格、偏好倾向）也会融入推理过程，使AI逐渐呈现出贴合该用户的个性化行为 。对于企业应用，MemOS甚至允许预设不同职位的角色模板，控制它们各自的**记忆权限和行为边界**，例如分析师、助手、项目经理等共享某些团队知识但又各有访问限制 。这解决了LLM**个性化**和**多身份一致性**的难题，让模型真正“记住你”和“扮演好对应的角色”。
4. **记忆孤岛与迁移问题**：当用户在不同应用或设备上使用AI时，互动产生的记忆往往**孤立地**留在各自平台，无法通用。例如，你手机助手积累的旅行喜好，在电脑上的办公助理上就无法获取，需要重复提供偏好信息。这造成知识和经验无法共享，整体智能体验割裂 。MemOS通过**标准化的记忆表示和跨平台协议**解决这个问题。所有记忆块都采用统一格式，并可选择性加密，支持通过**记忆挂载协议**在不同环境中迁移和加载 。例如，你在手机上构建的“家庭旅行偏好”记忆（包含航班时间偏好、酒店类型、预算等），可以移植到公司电脑上的差旅规划Agent，在获得授权后为你提供一致的建议 。MemOS打通了不同代理和设备间的记忆通道，**消除了“记忆孤岛”现象**，使记忆成为用户在各平台间**可携带**的资产 。这对于未来多Agent协同也至关重要——一个Agent学到的新知识可以封装为记忆块分享给其他Agent，从而实现**群体智能**的知识流动。



综上，MemOS正是为解决上述痛点而生。**根本原因**在于，过去LLM把“记忆”当作一种静态的、次要的成分，未给予足够重视 。MemOS通过架构设计，把记忆变成可调度、可监督、可演进的核心资源，从系统层面赋能LLM具备**长时认知和持续学习**的能力 。这对于迈向更高级的智能体（需要像人一样积累经验、个性化成长）是至关重要的一步。换句话说，有了MemOS，LLM才可能拥有“完整的一生”的记忆，而不仅是短暂的片刻记忆  。





## 技术原理与架构解析 (Technical Analysis and Architecture)

MemOS在技术上提出了一套完整的**记忆管理架构**，包括记忆的表示抽象、分类体系、核心组件模块和运行流程。下面将从核心概念到系统架构依次展开说明。





### 三类核心记忆与 MemCube 抽象

MemOS将LLM的记忆分为**三类核心类型**，分别是**参数记忆**、**激活记忆**和**明文记忆**  。这三类记忆性质各异，在传统LLM中分属截然不同的层面。MemOS的创新之处在于**统一管理**这些异构记忆，并允许它们之间转换融合 。先逐一介绍：



- **参数记忆（Parametric Memory）**：指嵌入在模型参数中的长期知识，即通过预训练或微调**固化**在神经网络权重中的信息 。它涵盖模型对语言、常识和各种任务技能的基础理解，是LLM零样本或少样本推理能力的根基 。参数记忆的特点是**隐式**（不易解释）、**难以更新**（需要重新训练或知识编辑） ，但**推理时无需检索**（模型直接凭参数产生结果）。在MemOS中，参数记忆不仅包括模型预训练得到的一般知识，还可以通过模块化方法**插件式注入特定领域知识**，例如使用LoRA等高效微调技术加载法律、医疗等专业模块，组成可复用的**领域技能** 。因此，MemOS将参数记忆视为模型的“内置知识库”，但允许通过模块化扩展来丰富和组合。
- **激活记忆（Activation Memory）**：指模型在推理过程中产生的**瞬时状态**，包括隐藏层激活、注意力权重以及KV缓存等 。这些激活状态携带着当前对话或任务的**上下文信息**，对模型的输出起重要调节作用，例如KV缓存可以使模型在长文本生成中保持连贯。但传统上这些状态是**短暂**且**一次性的**——推理一结束就丢弃。MemOS将激活记忆视为模型的“**工作记忆**”，用于临时存储正在处理的信息 。MemOS允许对激活记忆进行**动态调度**：例如，对于经常访问的激活模式（如某些对话上下文），可以将其提取成**半结构化片段**或固化为新的参数模块，从而让短期记忆也能**持久化**、随时间演化  。MemOS甚至支持在激活记忆与其他类型记忆间转换，如把频繁用到的激活状态转存成明文模板，加快下次重用时的解码效率 。因此，激活记忆在MemOS中不再仅仅是一次性缓存，而成为可缓存、可迁移的**动态记忆层**。
- **明文记忆（Plaintext Memory）**：指外部以可编辑形式存储的知识或信息，如文档、笔记、数据库记录、知识图谱节点、提示模板等 。相对于模型内部记忆，明文记忆的特点是**易于编辑**、**可共享**且**易于管控**（因为是显式的数据）。RAG所利用的资料、LangChain保存的对话历史，都属于明文记忆的范畴。明文记忆可以突破模型上下文窗口限制，随时**增加新知识**或**修改过时信息**，因此是实现模型快速更新和个性化的重要手段 。MemOS高度重视明文记忆，将其作为模型推理上下文的一部分，并提供**版本控制、访问控制**和**调用追踪**等机制，保证使用外部记忆时有据可查 。例如，每条明文记忆都可以打标签、设置权限（某用户可见等）、记录来源和更新时间 。这使明文记忆能够被**可靠地治理**，避免无序增长或不一致。明文记忆也是实现**多智能体协作**的基础，因其可共享性，可用于不同Agent之间**交换知识**。





MemOS通过一个统一的**记忆立方体（MemCube）**将上述三类记忆抽象为统一的基本单元 。每个MemCube包含**语义负载**（memory content，即具体的记忆内容，可以是文本片段、参数向量或激活张量）以及相应的**结构化元数据** 。元数据分为三类，用于实现**识别、管控和自适应**：



- **描述性元数据**：用于标识记忆单元及定义其语义角色，包括时间戳（创建或更新时间）、来源标识（如由哪个用户输入或哪个推理产生）、语义类型标签（如“用户偏好”“任务提示”“领域知识”等） 。这些信息方便检索和追踪记忆的来龙去脉。
- **治理属性**：用于在多用户多Agent环境下实现**安全受控**的记忆使用策略，包括访问权限（哪些角色/用户可访问）、生存周期策略（如TTL过期时间、使用频次衰减规则）、优先级，以及合规相关的标记如敏感级别标签、水印标识、访问日志等 。有了这些属性，MemOS可以确保记忆的使用符合权限和法规要求。例如，可以为某些记忆设置“只能本地使用不可共享”或“在闲置一段时间后自动归档”等策略。
- **行为指示器**：这是一组由系统自动收集的**运行时指标**，反映该记忆的使用模式，如被访问频率、与当前上下文的相关性得分、版本演化链等 。这些指标用于MemOS的动态调度决策和记忆演进。例如，MemOS监控到某明文记忆片段频繁被访问，则可触发将其**转化为激活模板**以减少重复解码开销（对应**Plaintext→Activation**转换) ；又或者某些知识长期稳定有用，则考虑**蒸馏进参数**以提升推理效率（**Plaintext/Activation→Parametric**转换) ；反之，检测到模型某部分参数很少用到或已过时，则可选择将其**外化**成明文以获得编辑灵活性（**Parametric→Plaintext**转换) 。通过这些行为反馈，MemCube具备了一定“**自适应**”能力，可以在策略控制下不断调整自身的形态和存储位置，以优化整体性能。可以将MemCube想象为一个“自我感知、持续适应的记忆对象” 。





通过MemCube的设计，MemOS实现了记忆的标准化封装和跨类型统一表征  。无论记忆来源于模型内部还是外部，都可以抽象为MemCube，以**同样的方式被调度和操作**。这为后续的记忆调度、治理和跨平台迁移奠定了基础。正如作者所言，MemCube使LLM的记忆空间成为一个**统一、可控、可演化**的整体 。图示上，三类记忆之间的转换路径构成了一个立方体的不同维度（参数-激活-明文之间的互相转化），所以称为记忆立方MemCube 。这也是MemOS名称中“OS”的由来：它提供类似操作系统对不同存储介质统一管理的功能，只不过对象从内存/硬盘变成了LLM的各种记忆形式。





### MemOS 模块化三层架构

在MemCube抽象之上，MemOS构建了一个**分层的模块化架构**来实现记忆的解析、调度和存储治理 。架构分为**接口层**、**操作层**和**基础设施层**三层，每层由若干组件组成，协同形成一个闭环的记忆管理流程  。图5展示了MemOS架构的概览 。下面按层次介绍主要组件和功能：



- **接口层（Interface Layer）**：这是MemOS与外部交互的入口，负责**解析自然语言请求、识别记忆相关意图，并触发标准化的记忆API调用** 。其中内置的关键模块是**MemReader**，它相当于一个智能解析器/监听器：当用户提供一个提示（问题或指令）或某个任务被触发时，MemReader会分析其中是否涉及记忆操作，如**需要查询以往信息**、**需要更新某项记录**等 。然后MemReader将用户请求翻译成**结构化的记忆操作指令**，调用MemOS提供的统一**记忆API**接口 。MemOS定义了多种Memory API，例如：Provenance API用于记录或查询记忆的来源标注，Update API用于更新/版本化记忆内容，LogQuery API用于查询记忆使用日志等 。所有这些API操作都会封装为对相应MemCube的操作，并受到权限控制机制的保护 。接口层还引入了**管道式的操作链机制**（pipeline） 。也就是说，一个复杂的记忆相关请求可以被拆解为一系列有序的子操作（例如“查询→更新→归档”这样的链），每个阶段输出通过MemCube传递给下一阶段，形成一个事务流 。这种设计允许MemOS灵活地处理多步骤的记忆交互，并支持**DAG形式的定制工作流**，方便在多模型协作场景下重用常见的操作模式 。简单类比：接口层就像**前台+调度中心**，将用户的自然语言需求翻译成MemOS内核能理解的操作序列，并按需要发起对后续组件的调用。

- **操作层（Operation Layer）**：这是MemOS的大脑和控制中心，负责**记忆的调度决策、生命周期管理和结构化组织** 。操作层包括多个核心组件：



- **MemScheduler**：记忆调度器，相当于**智能的记忆选择器**。它根据当前用户请求的上下文，以及系统/用户/任务级的策略，决定从庞大的记忆库中选取哪些记忆单元（参数、激活或明文）来参与本次推理 。MemScheduler支持可插拔的多种调度策略，例如最近最少使用（LRU）淘汰原则、基于语义相似度匹配当前查询、基于标签规则（如优先选取某用户的个人记忆）等 。通过MemScheduler，MemOS实现了对不同层次记忆的**按需调用**，确保模型在推理时既不会遗忘重要线索，也不会加载过多无关信息浪费资源。
- **MemLifecycle**：记忆生命周期管理器，将记忆的状态变化建模为一个状态机，提供**版本回滚**、**冻结**等机制来保证记忆演化的可审计和时序一致 。例如，当一条知识更新时，旧版本可以冻结存档备查，新版本生效；或者允许在需要时将记忆恢复到某一历史版本以检查演变过程 。这部分确保MemOS引入**时间维度**管理，让记忆既能不断更新又能保持**历史可追溯**。
- **MemOperator**：记忆操作器，负责**具体执行对记忆的组织和检索** 。它提供标签体系、图谱结构、分层分区等机制，对记忆库进行**混合的结构化+语义组织** 。例如，MemOperator可以将记忆构建成主题-子主题的层次树，并在需要时通过标签或关系**执行图查询**，也可以通过嵌入向量进行语义搜索 。MemOperator的结果（检索出的相关记忆MemCube集合）会反馈给MemScheduler，用于决定如何将这些记忆**注入推理**过程 。此外，MemOperator实现**中间层缓存**，对于频繁访问的记忆结果，会做缓存以加速下次调用 。可以说，MemOperator是MemOS的大型“记忆仓库管理员”，确保存储的海量记忆能够被高效地找到和利用。



这些操作层组件相互配合，使MemOS能够实现**有效的记忆结构化、精准的调用以及在复杂任务/多Agent情况下的稳健推理** 。操作层的作用类似**大脑皮层**：基于策略和反馈对记忆进行决策和处理。

- **基础设施层（Infrastructure Layer）**：这是MemOS底层提供可靠存储、权限控制和跨平台交互的支撑部分 。主要模块包括：



- **MemGovernance**：记忆治理模块，负责系统的**安全与合规**。它实现前述的访问权限校验、生命周期策略执行和审计日志等功能，确保在多用户环境下记忆操作符合预定规则 。MemGovernance好比操作系统的安全子系统，防止未授权的记忆访问或敏感信息泄露。例如，不同用户的记忆空间可以隔离，敏感记忆可以强制水印和日志记录等 。
- **MemVault**：记忆库/金库，负责对接各种底层存储后端，实现对**多样化记忆存储库**的统一访问 。现实中记忆可能存放在不同形式的数据库、文件系统、图数据库等，MemVault提供一个抽象层，将它们纳入统一命名空间并提供一致接口 。这样上层组件不用关心记忆具体存在哪里，由MemVault来管理**异构存储**。
- **MemLoader & MemDumper**：这两个组件处理记忆在不同平台或智能体间的**迁入/迁出** 。MemLoader用于从外部来源加载记忆到本地，MemDumper则将本地记忆导出备份或发送给他人 。它们确保在迁移过程中保持**上下文完整性**和一致性。例如，将某用户的记忆转移到另一代理时，通过MemLoader/Dumper可以打包相关MemCube，目标端加载后仍保持关联关系不丢失 。这正是支持跨平台迁移和共享的机制所在。
- **MemStore**：记忆存储库/市场，支持记忆单元的开放发布和订阅，方便**多模型知识共享**与**协同执行** 。可以把MemStore想象成一个记忆的发布-订阅中心，不同智能体可以在此上传某些可共享的记忆（如通用知识模块），或者订阅其他代理发布的记忆，从而实现知识交换 。这为未来**去中心化的记忆生态**埋下伏笔。





基础设施层保障了MemOS整体运行的**可信赖性和可扩展性**。通过治理模块提供安全控制，通过Vault适配各种存储，通过Loader/Dumper实现流转，通过Store搭建共享渠道，MemOS可以在各种真实环境中长久演化而不失控  。这一层类似操作系统的内核服务，为上层记忆操作提供**稳定高效的基础**。



**记忆I/O闭环**：MemOS的各层各模块通过MemCube接口连接起来，使得整个系统形成一个**闭环的记忆输入输出流程** 。从用户输入开始，经MemReader解析请求->MemScheduler决策检索->MemOperator获取记忆并注入推理->生成响应，同时可能有MemLifecycle更新状态->MemVault存档->（可选）MemStore发布共享，如此循环往复  。每个阶段的数据都是通过MemCube结构体传递，从而保持**上下文和权限信息不丢失** 。这种闭环设计保证无论记忆如何演变，**每次交互都会产出新的记忆，进入下一轮循环**，模型因此不断成长。正如作者所说，这形成了从输入到记忆激活、转换、存储再到复用的闭环流程，一切由声明式策略驱动，通过MemCube抽象来执行 。





### 系统执行流程概览

综合上述组件，MemOS的运行流程可以概括如下：

1. 当用户提出请求或某任务触发时，MemReader将其解析为Memory API调用，初始化一个记忆操作管道 。
2. 接着MemScheduler根据策略从MemVault中选择出**相关的MemCube集合**（可能包含过去对话内容、相关知识、甚至激活模式等） 。
3. 这些选出的记忆单元被**注入模型的推理上下文**中，参与当前的回答/决策生成 。在此过程中，MemOperator对记忆进行必要的结构化组织（如构建提示模板、附加背景知识）并由MemLifecycle管理记忆状态的改变 。
4. 当推理结束后，新产生的重要信息会通过MemLifecycle记录成新的MemCube存入MemVault，并由MemGovernance打上相应标签、日志等 。

如果需要共享或迁移，则通过MemStore/Loader/Dumper进行后续处理 。整个过程的每一步均通过标准化的MemCube接口进行，保证了**过程透明、可追踪**，也方便在每一步施加策略（例如是否允许某记忆出现在结果中等） 。

简单来说，MemOS执行一次交互时，就像有一个专门的**记忆操作系统**在后台工作：帮模型**提前想好要用哪些记忆**、**怎么用**，然后在模型输出后**妥善保存好新记忆**，为下次交互做好准备。而这一切对用户而言是无感知的：他们只会注意到模型回答变得**更连贯、更个性化**，且**长期进化**，而不会觉得每次对话都从零开始。这正是MemOS带来的核心价值。



## 实际案例与应用场景 (Cases and Applications)

虽然MemOS提出时间不久（2025年中发布），但其理念已在一些原型和实验中得到验证，并展现出令人鼓舞的效果。同时，其潜在应用场景非常广泛，从个人助手到企业知识管理都有用武之地。以下从**实验演示**和**应用设想**两个方面来介绍：



### 原型实验与性能验证

MemOS的作者团队实现了一个功能完备的**MemOS原型系统**并在论文中进行了评估 。他们首先验证了MemOS在**对话持续性和个性化**方面相对传统方案的提升：通过引入MemCube记忆单元和调度框架，MemOS系统相比经典的RAG方案能够更好地保持上下文、一致的人格和偏好，大幅改善长对话的连贯性和用户黏性 。例如，在一个持续对话任务中，MemOS可以正确记住用户早先提过的细节和喜好，而普通RAG往往会遗忘，需要用户重复提供 。同时，MemOS支持版本跟踪和权限控制的记忆操作，也**奠定了模块化知识管理的可能**，使多个助手之间共享知识成为现实 。这些效果在论文的Demo中有所展示。



在更严格的量化评测上，作者构建了一个**LoCoMo**长对话记忆基准，用LLM判官来评分模型在多类推理任务上的表现 。结果显示，MemOS在所有任务上均取得**SOTA成绩** 。具体而言，MemOS对比其他强基线（包括Mem0、LangChain Memory方案“LangMem”、Zep长记忆存储和OpenAI自带记忆方案等）在**单跳问答、多跳推理、开放域和时间推理**四大类任务中均排名第一 。尤其在**复杂推理**（如多跳推理和时间推理）场景下优势明显，表明MemOS的记忆管理显著提高了模型推理的连贯性和正确性 。此外，在**Temporal Reasoning（时序推理）这样需要理解事件先后关系的任务中，MemOS相对OpenAI全局上下文方案性能提升高达159%，整体准确率提升约39%，同时将token开销减少了约60%** 。这说明MemOS不仅提高了准确性，还通过智能调度记忆**减少了无效输入**，达到更高的效率。这些数据强有力地证明了MemOS架构的有效性。值得一提的是，MemOS由于有效地“遗忘”无关信息、保留关键记忆，推理时比简单拼接所有历史上下文更节省计算，**实现更优的性能-成本折中**  。这对实际应用非常重要。



MemOS原型还展示了一些有趣的**功能演示**。例如，一个“**文字解谜游戏**”Demo中，MemOS驱动的LLM可以在多轮猜词游戏里记住玩家提供的线索和自己的猜测历史，不会重复猜测，也不会违背已知线索 （该Demo作为MemCube模块发布时的展示）。这看似简单，却需要模型拥有短期记忆与长期策略的结合；MemOS正通过维护一个随对局进展更新的明文记忆清单，实现了这一点。此外，MemOS还与**互联网搜索**和**图数据库**结合进行了实验：例如集成了BochaAI的网络检索和NebulaGraph的图数据库，以验证MemOS能够统一调度**实时检索信息**和**结构化知识**作为明文记忆来源 。这些扩展实验表明，MemOS框架具有很强的**兼容性**，可以利用各种现有工具（搜索引擎、知识库等）来丰富模型的记忆体系。





### 场景案例与潜在落地

基于MemOS的能力，我们可以设想许多实际应用场景，在一些领域已经初步有了探索：



- **个性化AI助手**：这可能是MemOS最直接的用武之地。借助MemOS，一个**个人智能助理**可以真正记住用户的偏好、习惯和历史，对同一个用户越用越了解，提供日益贴心的服务 。例如，一个家庭管家AI在MemOS支持下，会记得你的家庭成员、过敏史、常买物品清单；当你说“帮我准备小明的生日”，它会回忆起去年的安排和小明喜欢什么  。又如健康顾问AI，可以长期保存你的健康数据和医嘱历史，给出个性化的运动和饮食建议。所有这些都需要AI有**长久、私人的记忆**。MemOS通过每个用户的专属MemCube存储这些信息，保障隐私的同时让助手具备**持续学习用户**的能力  。
- **企业知识管理与协作**：MemOS可用于构建企业内部的智能知识库和协作Agent网络 。例如，一个企业的客服AI，使用MemOS后可以记忆每位客户过去的问题和偏好，当老客户再次来询问时能快速定位历史记录，提供更精准的服务 。同时，MemOS的权限机制可确保不同客服只访问自己权限范围内的客户记忆，保障数据合规 。再比如企业内部多个部门的AI助手可以通过MemStore共享公共知识（如公司政策、产品信息），又各自维护私有记忆（如部门内部项目细节），在协作时彼此交换所需信息 。MemOS提供的**跨Agent记忆迁移**让这一切成为可能：一个销售AI在签合同过程中记录的客户需求，被移交给实施AI时，可以将相关MemCube迁移过去，让实施AI接手时就了解客户背景，无缝衔接服务  。此外，MemOS的合规标签和日志功能在企业环境下尤为重要，可满足审计和法规要求（例如GDPR中的可删除、可追踪要求）。总体来看，MemOS有潜力成为**企业大模型应用的记忆中枢**，提高信息复用效率，减少部门孤岛。
- **多智能体系统**：近年来自主Agent的兴起需要AI之间共享信息、协调行动。MemOS的记忆共享和市场机制正好提供了基础设施 。设想一个复杂任务由多个专长不同的Agent合作完成（例如一个管家AI+家庭安防AI+扫地机器人AI协同管理家庭），MemOS可以让它们将观察到的事件、决策经过写入共享MemStore，彼此订阅更新，从而形成**集体记忆**。比如管家AI记录“今天厨房地板有液体洒漏”，扫地机器人AI从MemStore得知后便及时去清理。这种**多Agent共享记忆**机制对于AI编队、分工合作至关重要  。一些研究（如Meta的**环形记忆代理**等）也在尝试类似思路，MemOS可以作为通用框架支持这类系统。
- **持续学习型应用**：MemOS的“知识演化”特性非常适合需要不断更新知识的AI。例如法律或医疗咨询助手需要追踪最新法规和指南，MemOS可以让相关机构直接将新文件作为记忆块发布到MemStore，并标记为可信官方来源 。助手收到更新后，在回答问题时就会优先采用新指南内容，无需等待模型再次训练 。类似地，金融AI可以每天从市场新闻中提取关键信息存入记忆，使其决策与时俱进。相比频繁fine-tune模型，MemOS提供了**低成本、高时效**的持续学习途径。
- **用户可控AI与多模态记忆**：MemOS还能应用在一些特殊场景，例如让用户**教导AI**。用户可以通过接口层的记忆API显式告诉AI一些信息“记住这个”，MemOS会将其存入个人明文记忆，并对后续对话生效（类似一种用户指导的RAG）。另外，MemOS天然支持多模态（因为MemCube的payload可以是图像、音频等向量），因此对于需要记忆图像或传感器信息的场景（如家庭机器人记忆家居物品摆放，安防AI记忆人脸等等）也有用武之地 。



总的来说，**MemOS的应用前景是广阔的**。正如业界评论所说，这标志着让AI系统从“**静态回答**”进化到“**持续成长**”的新阶段。个人助手将不再千篇一律，而是各自成为“越用越懂你”的朋友；企业AI将摆脱遗忘和 silo，成为团队智慧的一部分；多个AI将共享经验，协同解决复杂问题。MemOS赋予AI“**经验**”，这可能引发一系列创新应用。



当然，目前MemOS主要还是在原型和开源实验阶段。实现这些应用仍需大量工程工作和验证，但已有迹象表明，一些公司和社区开始尝试。例如，MemOS开源项目本身推出了**MemOS Playground**供开发者试用其记忆功能 ；开源社区也出现了对MemOS的关注和二次开发，如有开发者将MemOS与热门的LangChain、Letta(MemGPT)框架结合进行实验等。据报道，有创业公司正在探索用MemOS构建**具长记忆的企业聊天机器人**和**CRM助手**等产品（虽然具体案例未完全公开）。随着MemOS生态逐渐成熟，相信会涌现更多落地实例。





## 工程落地挑战与机会 (Engineering Challenges and Opportunities)

任何新架构在实际应用中都会面临挑战，MemOS也不例外。在将MemOS从论文和原型推向大规模生产时，需要克服以下问题，同时也孕育着相应的机遇：



**1. 系统复杂性与性能开销**：引入MemOS无疑增加了LLM应用的系统复杂度 。多了记忆解析、调度、存储等环节，意味着需要更多计算和存储资源，以及更复杂的工程实现。这可能带来**性能上的额外开销**，例如每次对话要进行记忆检索和注入，增加了延迟。尤其在高并发或实时要求高的场景，下述操作如何高效完成是挑战。此外，管理大量MemCube也可能占用不少内存和磁盘。**机会在于**：MemOS也提供了**性能优化空间**。一方面，通过**异步预取和缓存**（MemOS已经设计了Next-Scene Prediction机制，推理前预测需要的记忆预加载 ），可以隐藏部分延迟 。另一方面，由于MemOS有智能调度，实际上能减少不必要的上下文，这**节省的token**能抵消一部分开销（正如实验证明的，token总消耗下降了60% ）。工程上，还可利用**高效索引**（例如向量数据库、图数据库）来加速记忆检索；将部分MemOS组件并行化或在后台持续运行，避免阻塞主线程等。随着优化，MemOS完全有可能在**可接受的性能开销**下运行，并换来远超付出的性能收益（如更高准确性、更低重复成本）。



**2. 扩展性和存储管理**：随着时间推移，MemOS将积累海量记忆数据。如果不加以控制，记忆库可能无限增长，查询效率下降、存储成本上升。因此扩展性是大问题。MemOS提供了一些工具如生命周期策略（定期归档老旧记忆）、访问频率统计（淘汰冷门记忆）等  。但在工程实践中，还需要制定更详细的**记忆回收和压缩**策略。例如，可以定期对长期未用的MemCube进行**摘要压缩**，或离线训练一个记忆压缩模型，将大量冗余记忆浓缩成小规模的知识块（类似人脑睡眠整合记忆）。另外，不同类型记忆可以分层存储：热的短期激活记忆放在高速介质（RAM/GPU显存），冷的长期知识放在慢存储（磁盘/云存储），实现**分层存储架构**。这些都是OS领域成熟的思路，可迁移过来。**机遇在于**：如果解决好扩展性，MemOS会成为一个**持续积累价值**的系统——记忆越用越丰富，模型越用越聪明。这就像数据库随着数据增长变得更有用。对于企业来说，积累自己的“知识记忆库”是很有价值的资产。如果MemOS能够证明其扩展性，它可能成为新一代**AI数据基础设施**的一部分，类似大数据时代的数据湖，只不过存储的是AI与人的交互记忆和知识。



**3. 与现有基础设施集成**：大多数LLM应用已经有一套现成的基础设施（如使用现有的向量数据库、缓存机制、日志系统等）。引入MemOS需要考虑与这些现有组件的集成兼容。比如很多应用用向量DB实现RAG，如果换用MemOS，能否平滑对接？幸好MemOS在设计上比较模块化，MemVault可以**适配多种存储** ，MemOperator也能对接图数据库或第三方检索模块 。工程上需要为MemOS编写适配器，将常用的向量库（如Milvus、FAISS）、图数据库（NebulaGraph等）纳入MemOS统一接口。目前MemOS开源版本已经支持NebulaGraph等集成 。另一个整合点是**大模型接口**：MemOS需要与各种LLM模型协同，如OpenAI API、本地模型（HuggingFace）、甚至让模型本身配合（如MemGPT那样产生函数调用）。为此MemOS开源框架已做了API封装，兼容OpenAI、HuggingFace和Ollama等主流LLM服务 。但进一步，还需要**标准化记忆交互协议**（MIP）的广泛支持 。如果未来模型API本身提供标准的“memory”接口，那整合将容易得多。**机遇在于**：MemOS可能推动整个生态对**记忆接口**的重视，诞生统一标准。就像云计算有S3标准存储接口一样，也许AI时代会出现“MIP（Memory Interchange Protocol）”标准，允许不同模型/framework交换记忆 。MemOS团队已经在展望MIP的发展 。如果成功，将极大便利MemOS在各平台落地，并带动产业协同。



**4. 隐私与安全合规**：MemOS涉及存储大量用户交互数据和知识，这里面很可能包含敏感个人信息或商业机密。因此**隐私保护和安全合规**是一大挑战。不仅要防范外部攻击窃取记忆，还要防止**内部滥用**（如某用户的记忆被另一个不该访问的用户/Agent看到）。MemOS为此引入了多层保障：MemCube元数据带有**敏感度标签、水印**等 ；MemGovernance模块强制执行**访问控制**和记录审计日志 ；跨平台迁移时采用**加密和信任机制**确保安全传输 。尽管如此，工程上还需要做细致的工作：比如实现**端到端加密**（记忆在存储和传输中都是加密，只有在模型推理时解密使用），以及**遗忘机制**（满足GDPR要求，用户请求删除时能彻底清除相关记忆）。此外，要防范**数据中毒**：恶意用户写入伪造记忆影响模型行为——这需要MemOS的权限和审核工作流来阻止，可引入类似数据库中的**审批**机制，对于影响全局的重要记忆更新需人工审核。**机遇**是，如果MemOS能够提供强有力的隐私保障，它将比现有粗放的RAG方案更**受企业和监管欢迎**。尤其是在金融、医疗等敏感领域，有了MemOS的精细权限管理，企业可以更放心地积累AI记忆，而不用担心数据泄露或不合规。这可能成为MemOS商业化的一大卖点：**“智能且合规的记忆管理”**。



**5. 模型认知与算法挑战**：MemOS从框架上给予模型记忆，但模型是否能充分利用这些记忆，仍需要算法上的配合。目前MemOS主要通过在prompt中注入相关记忆文本/信息来影响LLM输出。这属于**前馈式**影响。如果模型对注入内容重视不够，可能仍出现遗忘或不一致。所以未来可能需要在**模型训练**或**微调**层面配合MemOS。例如，训练LLM学会调用MemOS提供的API（类似MemGPT方法，让模型自己决定什么时候读/写记忆）。或者以**RLHF**方式，让模型明白保持一致性、遵守记忆的重要性。还有对**记忆重要性的理解**：目前MemOS是用访问频率等简单指标衡量，但真正重要的信息可能访问频率不高却关键，这需要更高级的认知判断。解决这个需要引入**元认知模型**或者**记忆重要性估计**算法。**机遇**在于：这其实打开了一个新的研究方向——**“记忆增强模型训练”**（Memory Training）。如同人类通过记忆巩固提高认知，未来模型训练可能也不只是优化预测下一个词，而是优化在长期交互中如何选择和存储信息。MemOS提供了基础设施，研究者可以尝试设计新的训练目标，让模型在使用MemOS时表现最佳。比如奖励模型合理读写MemCube、惩罚其遗忘用户提及的信息等等。这将推动LLM从结构上和行为上更加“会记忆”，进一步逼近AGI。



综上，MemOS在工程落地上有不少挑战，但每个挑战背后也预示着重大的机会。随着社区和产业对**大模型长效记忆**的需求日益增长，我们有理由相信这些问题会逐步解决。正如当初分布式数据库在克服扩展和一致性挑战后成为现代IT基石一样，**记忆操作系统**或将成为未来AI系统不可或缺的一环。而先行者MemOS在这一过程中积累的技术，将成为其差异化优势。





## 未来展望 (Future Directions)

MemOS的提出标志着LLM体系架构向**记忆中心**转变的开始。展望未来，这一领域有若干值得关注的发展趋势和潜在方向：



- **技术趋势：标准化与生态融合** – 如前所述，一个可能的趋势是出现**记忆互通的行业标准**（Memory Interchange Protocol, MIP） 。如果OpenAI、谷歌等也在其API中支持标准的记忆读写接口，不同模型间共享记忆将更加容易。MemOS团队计划扩展MIP定义标准格式、兼容规则和信任机制，以实现跨模型、跨应用的记忆安全传输 。这种标准一旦形成，记忆就能像今日的数据文件一样在平台间流通，催生新的生态。另外，**模型架构本身**也可能朝记忆友好方向演进。例如，未来的Transformer可能内置长短期记忆模块，可直接与MemOS交互，而无需完全依赖prompt插入。这类似于在神经网络中嵌入可读写的记忆单元（如Neural Turing Machine等思想）。标准化和架构演进相辅相成，将加速记忆OS理念的普及。
- **潜在标准化与联盟** – 业界可能出现**Memory-OS联盟或开源社区**，共同完善相关协议和实现。这类似于当年Android联盟或ONNX标准的出现。MemOS目前已开源并获得社区关注  （HuggingFace上有较多收藏和点赞 ），未来或许能成为事实标准。当然也可能有其他团队推出类似框架，产生竞争与融合。比如开发者UglyToilet在HuggingFace上发布了MemOS的扩展版本并用中英文详细介绍  ，这表明社区正在消化吸收这一概念。一个统一的标准将使**记忆模块成为AI应用的标配**，如同数据库之于应用开发。
- **自进化记忆单元** – 作者提出未来要研发**自我优化和演化的记忆块（MemBlocks）** 。这意味着记忆单元本身能够根据使用反馈自动完善和调整。例如，一个知识MemCube被频繁访问但总出现一些错误引用，它可以自主纠错或补充信息；又如某对话记忆察觉自己常被忽略，可能自动生成更精炼的摘要以提高存在感。实现这种能力需要结合强化学习或元学习算法，使MemCube具备一定的**自治学习**能力。虽然听起来有些科幻，但这和人脑的记忆巩固、反思机制有类似之处。若成功，将减少人工维护，大幅提升系统自治性 。
- **记忆交易与共享市场** – 一个令人兴奋又需谨慎的展望是建立**去中心化的记忆市场** 。MemOS团队提到希望支持记忆作为一种资产进行交易、协作更新和分布式演化 。可以想象，将来可能出现类似App Store的“Memory Store”，开发者/公司可以上传特定领域的高质量记忆包（例如医学知识库MemCube集合、法律条款MemCube集合），有需求的用户或AI代理可以购买/订阅这些记忆，从而快速获得新能力。这相当于**知识即服务**的新模式。当然，这也带来知识产权和安全问题，需要完善的权限和溯源机制（这正是MemOS关注的）。如果妥善实现，记忆市场将大大**加速知识共享**，让每个AI不必从零学习所有知识，而是可以像人类社会那样**通过交流获取经验**。这对整体AI能力提升具有重大意义。
- **产业化前景** – 从产业角度，MemOS理念成熟后，可能有多种商业落地形式：1）**MemOS企业版**：针对企业内部使用，提供私有部署的记忆管理系统，与企业内部数据/知识库无缝结合，强调数据主权和隐私。2）**MemOS云服务**：作为第三方平台，开发者将其LLM应用接入MemOS云，快速获得记忆能力，无需自己搭建复杂后端。这类似于提供“Memory Backend as a Service”。3）**嵌入式MemOS**：与模型厂商或大平台合作，将MemOS功能嵌入他们的AI平台。比如未来某云厂商的大模型服务直接内置MemOS模块，用户勾选即可启用长久记忆功能。总之，谁能率先提供稳定易用的记忆解决方案，谁将在企业AI市场赢得优势。目前看到的动向是，像Zep、LangChain这样的公司也在探索长对话记忆管理的产品形态，MemOS作为学术和开源项目，有机会与他们合作或成为底层标准。
- **与认知科学的融合** – 最后，从更远的角度，MemOS的出现也许预示着**AI架构与人类认知架构的进一步靠拢**。人类的智能离不开记忆，短期工作记忆、长期记忆、情景记忆等等相辅相成。AI早期更多关注推理能力，如今开始补齐记忆这一块短板，今后可能还会引入类似情感记忆、模糊记忆等概念。研究者可以从认知科学借鉴灵感，例如**情境记忆**（让AI对特定环境、场景形成记忆上下文），**遗忘机制**（有选择地遗忘无用信息以保持效率）等。MemOS提供了一个工程框架，让这些想法可以在AI中试验。随着理解加深，未来AI的“记忆OS”可能变得更像**生物大脑的记忆系统**，具备更高层次的理解和自省能力。





**总结展望**：MemOS开启了一个让AI系统具备持久记忆的新篇章。从当前看，它满足了实际应用的迫切需求（长对话、一致性、个性化等），也为诸多创新应用提供了可能性。从长远看，它为打造更接近人类的AI agent铺平了道路。未来几年，我们可能会看到记忆管理从一个新奇概念变成AI应用的**标配**。回顾过去，计算机领域经历了从无操作系统到有操作系统的飞跃，极大地提升了效率和功能；那么在AI领域，MemOS这样的“记忆操作系统”是否也会带来类似的范式转变？目前迹象是积极的。当然，要真正兑现其潜力，还需要持续的研究与实践投入。但可以肯定的是，**让AI学会“记得”**，将是迈向更高智能形态的关键一步。让我们拭目以待MemOS及其后继者如何塑造未来的智能应用生态。





## 结论 (Conclusion)

本文详细调研了MemOS——一套面向大语言模型的记忆操作系统，从定义理念到架构实现，再到应用前景和挑战进行了全面分析。**MemOS的核心**是在LLM中引入统一的记忆管理机制，把参数、激活和明文三类记忆作为可调度治理的资源，透过MemCube抽象和三层架构，实现了记忆的生成、组织、利用和演化的全流程管理  。它弥补了传统LLM在长期记忆、知识更新、个性化和多Agent协作方面的不足，使模型能够“记住过去、适应现在、规划未来”。



对比其他方案，MemOS并非孤立的点袭创新，而是对现有记忆增强思路的一次系统性整合和提升：相比RAG，它提供了结构化的记忆生命周期控制  ；相比LangChain Memory等应用层方案，它建立了模型级的记忆框架，支持更复杂的记忆类型和策略；相比MemGPT、Mem0等特定实现，MemOS展现出统一调度、多角色融合和跨平台演化的野心，体现出**操作系统式的通用性**。当然，MemOS也还处于早期，面对工程实现和推广有不少挑战，如性能优化、数据隐私、生态构建等。但这些挑战正在被认识和解决中。MemOS开源以来的实验和社区反馈显示，它确实**增强了LLM的推理连贯性和个性化**，在长对话等任务上达到新的SOTA 。这证明“让模型拥有操作系统级的记忆”并非纸上谈兵，而是切实可行且收益显著的方向。



我们也展望了未来发展：随着更多研究者和企业投入，记忆管理框架可能逐步标准化、产业化。无论名称是否是MemOS，可以预见**记忆中枢**将成为下一代AI系统的重要组成部分，使得AI从一次性工具进化为能持续学习成长的智能体【32†L197- L199】。正如本文标题所示，MemOS代表的正是**Memory-Augmented Generation**的新范式，即**将生成式AI与记忆机制深度融合**。这可能引领AI领域出现新的研究浪潮和应用模式。长期来看，一个具备可靠长期记忆并能自主管理知识的AI，才有望逼近我们对类人智能的期望。



总而言之，MemOS开创性地填补了LLM架构中的记忆缺环，在学术上具有里程碑意义，在工程上提供了实践框架，在应用上孕育着丰富机会。当然，它也有自身局限和需要完善之处，例如目前尚未解决如何理解记忆的重要性、情感因素等更高层问题 。但瑕不掩瑜，MemOS的出现无疑推动了AGI道路上的关键一步。未来，我们期待在社区和产业共同努力下，涌现更多创新，让MemOS理念不断进化，最终成熟为AI时代的“记忆操作系统”标准，让每个AI都能拥有完备的一生记忆，真正实现“知古鉴今，持续学习”的智能。正如一句话所说：**Intelligence begins with memory（智能始于记忆）** 。MemOS正在将此愿景变为现实。



**参考文献：**



- Li, Zhiyu, *et al*. *MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models (Short Version)*. arXiv preprint arXiv:2505.22101, 2025        .
- Li, Zhiyu, *et al*. *MemOS: A Memory OS for AI System (Long Version)*. arXiv preprint arXiv:2507.03724, 2025            .
- Packer, Charles, *et al*. *MemGPT: Towards LLMs as Operating Systems*. arXiv preprint arXiv:2310.08560, 2023   .
- Chhikara, Prateek, *et al*. *Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory*. arXiv preprint arXiv:2504.19413, 2025  .
- **LangChain Documentation (中文)** – 记忆模块介绍  .
- **36Kr Tech News (机器之心)** – *“重塑记忆架构：LLM正在安装『操作系统』”*, Jul 2025 .
- **HuggingFace Papers** – MemOS (Chinese summary by UglyToilet)   .
- **Medium Blog** – *AI Made Relatable — MemOS (Short Version)* by Yashraj Gore, Jul 2025   .
- **CSDN技术博客** – *MemGPT论文详解* (Chinese) by xieyan0811, May 2024 .
- **博客园** – *深入浅出分析Mem0个性化AI记忆层* by JadePeng, Aug 2025  .
- **MemOS 官方网站** – *INTELLIGENCE BEGINS WITH MEMORY*, Memtensor Inc., 2025 .